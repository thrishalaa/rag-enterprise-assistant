
# ğŸ“˜ Enterprise Knowledge Base â€“ Local RAG Assistant

A fully offline, open-source **Retrieval-Augmented Generation (RAG)** system built with **FastAPI**, **FAISS**, **Sentence-Transformers**, and a **local LLM** using llama.cpp (DeepSeek-R1 Distill Qwen 1.5B GGUF).
Supports document ingestion, semantic search, reranking, evaluation metrics, and a complete Streamlit UI.

---

## ğŸš€ Features

* ğŸ”’ **Completely offline** â€“ Runs fully on CPU with local GGUF model
* ğŸ“„ **Document ingestion** (PDF, TXT, Markdown)
* âœ‚ï¸ **Text chunking** with configurable size & overlap
* ğŸ” **Semantic search** using FAISS vector database
* ğŸ§  **RAG pipeline** with context-grounded answering using local LLM
* ğŸ¯ **Reranking** using Cross-Encoder (ms-marco-MiniLM-L6-v2)
* ğŸ“Š **Evaluation tools**: Recall@k, Precision@k, MRR, Human eval logs
* ğŸ–¥ï¸ **Streamlit UI** for uploading documents and chatting with the assistant
* ğŸ” **Configurable via `.env`** (model path, embedding model, etc.)

---

## ğŸ— Architecture Overview

```
User â†’ Streamlit UI â†’ FastAPI Backend â†’ FAISS Vector Store
                                 â†“
                         Cross-Encoder Reranker
                                 â†“
                       Local LLM via llama.cpp
                                 â†“
                            Final Answer
```

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ app/
â”‚   â”‚   â”œâ”€ api/               # /chat, /ingest, /search endpoints
â”‚   â”‚   â”œâ”€ services/          # embedder, vector store, LLM client, reranker
â”‚   â”‚   â””â”€ main.py            # FastAPI app entrypoint
â”‚   â”œâ”€ ingestion/             # loaders, text splitter
â”‚   â”œâ”€ evaluation/            # recall@k, MRR, human evaluation logs
â”‚   â””â”€ utils/                 # config, logger
â”‚
â”œâ”€ ui/
â”‚   â””â”€ streamlit_app.py       # Web UI for upload & chat
â”‚
â”œâ”€ models/                    # GGUF models (not included)
â”œâ”€ data/                      # FAISS index, metadata, uploads
â”œâ”€ .env                       # environment variables (not included)
â”œâ”€ .gitignore
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/rag-enterprise-assistant.git
cd rag-enterprise-assistant
```

### 2. Install dependencies

```
pip install -r requirements.txt
```

### 3. Download a GGUF model

Example (DeepSeek-R1 Distill Qwen 1.5B Q4_K_M):

Place the file here:

```
models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf
```

### 4. Create a `.env` file

```
EMBEDDER_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLAMA_MODEL_PATH=models/deepseek/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf
SECRET_KEY=your_secret_key_here
CHUNK_SIZE=2000
CHUNK_OVERLAP=300
```

---

## â–¶ï¸ Running the Application

### Start the FastAPI backend:

```
uvicorn src.app.main:app --reload --port 8000
```

### Start the Streamlit UI:

```
streamlit run ui/streamlit_app.py
```

The UI runs at:

ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

Backend runs at:

ğŸ‘‰ [http://localhost:8000](http://localhost:8000)

---

## ğŸ“¤ Ingest Documents

Use Streamlit UI or:

```
POST /ingest
```

---

## ğŸ” Semantic Search

```
GET /search?q=your question
```

---

## ğŸ’¬ Chat with the Assistant

```
GET /chat?q=your question
```

Uses:

* FAISS top-20 retrieval
* Cross-encoder reranking
* LLM inference via llama.cpp
* Final grounded answer

---

## ğŸ“ˆ Evaluation Tools

Run retrieval evaluation:

```
python src/evaluation/retrieval_eval.py
```

Includes:

* Recall@k
* Precision@k
* MRR
* FAISS vs Reranker comparison

Human evaluation logs stored in:

```
evaluation/human_eval_log.jsonl
```

---

## ğŸ§© Tech Stack

* **FastAPI** â€“ backend API
* **FAISS** â€“ vector database
* **Sentence-Transformers** â€“ embeddings
* **Cross-Encoder** â€“ reranking
* **llama.cpp / llama-cpp-python** â€“ local LLM
* **Streamlit** â€“ UI
* **Python** â€“ core language

---

## âš ï¸ Note

Model files (`.gguf`) and FAISS index files are **not included** due to size.

---

## âœ¨ Future Improvements

* PDF preview in UI
* Chat history
* Multi-user sessions
* Admin dashboard
* Improved ranking with multi-vector retrieval

---

